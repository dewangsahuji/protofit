{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Media pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.arr  # Press Tab after \"arr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'cv2.VideoCapture' object has no attribute 'destroyAllWindows'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     36\u001b[39m cap.release()\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mcap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdestroyAllWindows\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'cv2.VideoCapture' object has no attribute 'destroyAllWindows'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Start capturing video\n",
    "cap = cv2.VideoCapture(0) # Use 0 for webcam, or provide a video file path\n",
    "\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret ,frame = cap.read()\n",
    "    if not ret :\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB (MediaPipe requires RGB format)\n",
    "    rgb_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Get pose landmarks\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    # Draw pose landmarks\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame,results.pose_landmarks,mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # Show output\n",
    "    cv2.imshow(\"Pose Datection\",frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cap.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MediaPipe detects 33 keypoints (landmarks) on the body.\n",
    "Some important ones:\n",
    "\n",
    "    Nose: results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE]\n",
    "    Shoulders: LEFT_SHOULDER, RIGHT_SHOULDER\n",
    "    Elbows: LEFT_ELBOW, RIGHT_ELBOW\n",
    "    Knees: LEFT_KNEE, RIGHT_KNEE\n",
    "\n",
    "Full list: MediaPipe Pose Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üõ†Ô∏è Step 4: Print Shoulder Coordinates & Save Video\n",
    "\n",
    "Now, let‚Äôs modify the script to:\n",
    "\n",
    "‚úÖ Print left & right shoulder coordinates (x, y).\n",
    "\n",
    "‚úÖ Save the pose-detected video using cv2.VideoWriter()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Shoulder: (523, 391), Right Shoulder: (214, 388)\n",
      "Left Shoulder: (525, 394), Right Shoulder: (211, 399)\n",
      "Left Shoulder: (525, 395), Right Shoulder: (210, 401)\n",
      "Left Shoulder: (525, 396), Right Shoulder: (209, 402)\n",
      "Left Shoulder: (526, 396), Right Shoulder: (208, 403)\n",
      "Left Shoulder: (526, 397), Right Shoulder: (208, 403)\n",
      "Left Shoulder: (526, 398), Right Shoulder: (208, 404)\n",
      "Left Shoulder: (526, 398), Right Shoulder: (208, 403)\n",
      "Left Shoulder: (526, 398), Right Shoulder: (208, 403)\n",
      "Left Shoulder: (526, 398), Right Shoulder: (208, 403)\n",
      "Left Shoulder: (527, 398), Right Shoulder: (208, 403)\n",
      "Left Shoulder: (527, 398), Right Shoulder: (208, 403)\n",
      "Left Shoulder: (527, 398), Right Shoulder: (208, 403)\n",
      "Left Shoulder: (527, 398), Right Shoulder: (207, 403)\n",
      "Left Shoulder: (528, 399), Right Shoulder: (208, 403)\n",
      "Left Shoulder: (529, 399), Right Shoulder: (208, 403)\n",
      "Left Shoulder: (530, 399), Right Shoulder: (210, 403)\n",
      "Left Shoulder: (530, 398), Right Shoulder: (211, 403)\n",
      "Left Shoulder: (532, 397), Right Shoulder: (212, 404)\n",
      "Left Shoulder: (532, 393), Right Shoulder: (213, 404)\n",
      "Left Shoulder: (532, 392), Right Shoulder: (214, 404)\n",
      "Left Shoulder: (532, 388), Right Shoulder: (214, 404)\n",
      "Left Shoulder: (532, 388), Right Shoulder: (215, 404)\n",
      "Left Shoulder: (533, 386), Right Shoulder: (215, 405)\n",
      "Left Shoulder: (535, 386), Right Shoulder: (215, 405)\n",
      "Left Shoulder: (536, 385), Right Shoulder: (215, 405)\n",
      "Left Shoulder: (537, 384), Right Shoulder: (215, 405)\n",
      "Left Shoulder: (537, 381), Right Shoulder: (215, 405)\n",
      "Left Shoulder: (537, 375), Right Shoulder: (215, 405)\n",
      "Left Shoulder: (537, 373), Right Shoulder: (215, 406)\n",
      "Left Shoulder: (537, 373), Right Shoulder: (215, 406)\n",
      "Left Shoulder: (536, 372), Right Shoulder: (215, 407)\n",
      "Left Shoulder: (536, 372), Right Shoulder: (215, 407)\n",
      "Left Shoulder: (535, 371), Right Shoulder: (215, 407)\n",
      "Left Shoulder: (534, 371), Right Shoulder: (215, 407)\n",
      "Left Shoulder: (534, 373), Right Shoulder: (214, 407)\n",
      "Left Shoulder: (534, 374), Right Shoulder: (214, 408)\n",
      "Left Shoulder: (534, 377), Right Shoulder: (214, 408)\n",
      "Left Shoulder: (534, 379), Right Shoulder: (214, 408)\n",
      "Left Shoulder: (534, 383), Right Shoulder: (212, 408)\n",
      "Left Shoulder: (534, 389), Right Shoulder: (211, 406)\n",
      "Left Shoulder: (534, 396), Right Shoulder: (210, 403)\n",
      "Left Shoulder: (529, 403), Right Shoulder: (216, 341)\n",
      "Left Shoulder: (529, 406), Right Shoulder: (219, 335)\n",
      "Left Shoulder: (529, 406), Right Shoulder: (221, 336)\n",
      "Left Shoulder: (529, 407), Right Shoulder: (224, 340)\n",
      "Left Shoulder: (530, 406), Right Shoulder: (224, 345)\n",
      "Left Shoulder: (531, 406), Right Shoulder: (224, 347)\n",
      "Left Shoulder: (531, 406), Right Shoulder: (224, 348)\n",
      "Left Shoulder: (534, 406), Right Shoulder: (225, 349)\n",
      "Left Shoulder: (536, 406), Right Shoulder: (225, 350)\n",
      "Left Shoulder: (538, 406), Right Shoulder: (225, 356)\n",
      "Left Shoulder: (539, 405), Right Shoulder: (225, 359)\n",
      "Left Shoulder: (540, 404), Right Shoulder: (225, 362)\n",
      "Left Shoulder: (541, 402), Right Shoulder: (225, 365)\n",
      "Left Shoulder: (543, 399), Right Shoulder: (225, 369)\n",
      "Left Shoulder: (544, 397), Right Shoulder: (225, 372)\n",
      "Left Shoulder: (545, 395), Right Shoulder: (225, 373)\n",
      "Left Shoulder: (545, 392), Right Shoulder: (225, 372)\n",
      "Left Shoulder: (544, 391), Right Shoulder: (225, 372)\n",
      "Left Shoulder: (543, 390), Right Shoulder: (225, 371)\n",
      "Left Shoulder: (542, 390), Right Shoulder: (225, 367)\n",
      "Left Shoulder: (541, 390), Right Shoulder: (225, 365)\n",
      "Left Shoulder: (539, 392), Right Shoulder: (224, 362)\n",
      "Left Shoulder: (538, 393), Right Shoulder: (223, 361)\n",
      "Left Shoulder: (538, 396), Right Shoulder: (223, 361)\n",
      "Left Shoulder: (537, 396), Right Shoulder: (225, 361)\n",
      "Left Shoulder: (538, 396), Right Shoulder: (225, 367)\n",
      "Left Shoulder: (538, 396), Right Shoulder: (224, 370)\n",
      "Left Shoulder: (538, 396), Right Shoulder: (224, 376)\n",
      "Left Shoulder: (538, 391), Right Shoulder: (224, 384)\n",
      "Left Shoulder: (538, 389), Right Shoulder: (223, 388)\n",
      "Left Shoulder: (539, 381), Right Shoulder: (224, 392)\n",
      "Left Shoulder: (542, 371), Right Shoulder: (226, 395)\n",
      "Left Shoulder: (544, 366), Right Shoulder: (228, 397)\n",
      "Left Shoulder: (545, 358), Right Shoulder: (231, 398)\n",
      "Left Shoulder: (545, 353), Right Shoulder: (234, 399)\n",
      "Left Shoulder: (545, 351), Right Shoulder: (234, 400)\n",
      "Left Shoulder: (545, 349), Right Shoulder: (235, 401)\n",
      "Left Shoulder: (543, 347), Right Shoulder: (234, 400)\n",
      "Left Shoulder: (542, 349), Right Shoulder: (232, 400)\n",
      "Left Shoulder: (542, 353), Right Shoulder: (230, 395)\n",
      "Left Shoulder: (541, 359), Right Shoulder: (224, 391)\n",
      "Left Shoulder: (541, 364), Right Shoulder: (222, 388)\n",
      "Left Shoulder: (538, 375), Right Shoulder: (219, 382)\n",
      "Left Shoulder: (537, 386), Right Shoulder: (215, 377)\n",
      "Left Shoulder: (536, 390), Right Shoulder: (213, 375)\n",
      "Left Shoulder: (534, 393), Right Shoulder: (213, 368)\n",
      "Left Shoulder: (534, 402), Right Shoulder: (212, 366)\n",
      "Left Shoulder: (532, 406), Right Shoulder: (209, 365)\n",
      "Left Shoulder: (531, 407), Right Shoulder: (208, 364)\n",
      "Left Shoulder: (531, 407), Right Shoulder: (209, 363)\n",
      "Left Shoulder: (531, 407), Right Shoulder: (209, 363)\n",
      "Left Shoulder: (531, 406), Right Shoulder: (209, 364)\n",
      "Left Shoulder: (531, 405), Right Shoulder: (209, 364)\n",
      "Left Shoulder: (531, 405), Right Shoulder: (209, 367)\n",
      "Left Shoulder: (531, 403), Right Shoulder: (209, 370)\n",
      "Left Shoulder: (532, 399), Right Shoulder: (209, 372)\n",
      "Left Shoulder: (532, 397), Right Shoulder: (209, 374)\n",
      "Left Shoulder: (532, 394), Right Shoulder: (210, 377)\n",
      "Left Shoulder: (532, 388), Right Shoulder: (210, 379)\n",
      "Left Shoulder: (532, 384), Right Shoulder: (212, 379)\n",
      "Left Shoulder: (535, 382), Right Shoulder: (214, 379)\n",
      "Left Shoulder: (536, 381), Right Shoulder: (215, 379)\n",
      "Left Shoulder: (537, 372), Right Shoulder: (218, 378)\n",
      "Left Shoulder: (537, 359), Right Shoulder: (220, 375)\n",
      "Left Shoulder: (537, 353), Right Shoulder: (222, 370)\n",
      "Left Shoulder: (537, 348), Right Shoulder: (223, 367)\n",
      "Left Shoulder: (538, 348), Right Shoulder: (224, 364)\n",
      "Left Shoulder: (537, 348), Right Shoulder: (224, 363)\n",
      "Left Shoulder: (538, 348), Right Shoulder: (224, 363)\n",
      "Left Shoulder: (538, 348), Right Shoulder: (224, 362)\n",
      "Left Shoulder: (539, 348), Right Shoulder: (223, 363)\n",
      "Left Shoulder: (539, 349), Right Shoulder: (223, 363)\n",
      "Left Shoulder: (539, 354), Right Shoulder: (222, 364)\n",
      "Left Shoulder: (539, 357), Right Shoulder: (221, 364)\n",
      "Left Shoulder: (539, 363), Right Shoulder: (220, 366)\n",
      "Left Shoulder: (539, 364), Right Shoulder: (221, 366)\n",
      "Left Shoulder: (540, 365), Right Shoulder: (221, 366)\n",
      "Left Shoulder: (541, 365), Right Shoulder: (221, 366)\n",
      "Left Shoulder: (541, 363), Right Shoulder: (221, 365)\n",
      "Left Shoulder: (541, 361), Right Shoulder: (221, 363)\n",
      "Left Shoulder: (541, 360), Right Shoulder: (221, 362)\n",
      "Left Shoulder: (541, 356), Right Shoulder: (221, 361)\n",
      "Left Shoulder: (541, 351), Right Shoulder: (222, 359)\n",
      "Left Shoulder: (540, 347), Right Shoulder: (222, 358)\n",
      "Left Shoulder: (539, 347), Right Shoulder: (222, 357)\n",
      "Left Shoulder: (539, 347), Right Shoulder: (222, 357)\n",
      "Left Shoulder: (539, 347), Right Shoulder: (222, 356)\n",
      "Left Shoulder: (539, 347), Right Shoulder: (222, 356)\n",
      "Left Shoulder: (538, 347), Right Shoulder: (222, 355)\n",
      "Left Shoulder: (538, 347), Right Shoulder: (221, 355)\n",
      "Left Shoulder: (537, 348), Right Shoulder: (221, 355)\n",
      "Left Shoulder: (537, 348), Right Shoulder: (220, 355)\n",
      "Left Shoulder: (537, 348), Right Shoulder: (220, 356)\n",
      "Left Shoulder: (537, 349), Right Shoulder: (219, 356)\n",
      "Left Shoulder: (537, 350), Right Shoulder: (219, 356)\n",
      "Left Shoulder: (537, 355), Right Shoulder: (218, 358)\n",
      "Left Shoulder: (537, 359), Right Shoulder: (217, 360)\n",
      "Left Shoulder: (537, 361), Right Shoulder: (217, 361)\n",
      "Left Shoulder: (536, 370), Right Shoulder: (215, 367)\n",
      "Left Shoulder: (536, 382), Right Shoulder: (214, 374)\n",
      "Left Shoulder: (535, 384), Right Shoulder: (214, 380)\n",
      "Left Shoulder: (535, 384), Right Shoulder: (214, 383)\n",
      "Left Shoulder: (535, 384), Right Shoulder: (214, 382)\n",
      "Left Shoulder: (534, 384), Right Shoulder: (213, 384)\n",
      "Left Shoulder: (534, 384), Right Shoulder: (212, 385)\n",
      "Left Shoulder: (534, 384), Right Shoulder: (212, 385)\n",
      "Left Shoulder: (534, 385), Right Shoulder: (212, 384)\n",
      "Left Shoulder: (533, 384), Right Shoulder: (212, 384)\n",
      "Left Shoulder: (533, 384), Right Shoulder: (212, 384)\n",
      "Left Shoulder: (533, 384), Right Shoulder: (212, 384)\n",
      "Left Shoulder: (533, 384), Right Shoulder: (211, 385)\n",
      "Left Shoulder: (533, 384), Right Shoulder: (210, 386)\n",
      "Left Shoulder: (533, 385), Right Shoulder: (210, 388)\n",
      "Left Shoulder: (534, 385), Right Shoulder: (210, 389)\n",
      "Left Shoulder: (533, 386), Right Shoulder: (210, 390)\n",
      "Left Shoulder: (533, 386), Right Shoulder: (210, 390)\n",
      "Left Shoulder: (533, 386), Right Shoulder: (210, 391)\n",
      "Left Shoulder: (533, 386), Right Shoulder: (210, 391)\n",
      "Left Shoulder: (532, 387), Right Shoulder: (210, 391)\n",
      "Left Shoulder: (532, 387), Right Shoulder: (210, 391)\n",
      "Left Shoulder: (531, 387), Right Shoulder: (209, 391)\n",
      "Left Shoulder: (531, 387), Right Shoulder: (209, 392)\n",
      "Left Shoulder: (530, 387), Right Shoulder: (208, 392)\n",
      "Left Shoulder: (530, 387), Right Shoulder: (206, 394)\n",
      "Left Shoulder: (530, 388), Right Shoulder: (206, 394)\n",
      "Left Shoulder: (530, 388), Right Shoulder: (205, 394)\n",
      "Left Shoulder: (529, 388), Right Shoulder: (205, 394)\n",
      "Left Shoulder: (529, 388), Right Shoulder: (204, 394)\n",
      "Left Shoulder: (528, 388), Right Shoulder: (204, 394)\n",
      "Left Shoulder: (528, 388), Right Shoulder: (203, 394)\n",
      "Left Shoulder: (527, 388), Right Shoulder: (203, 394)\n",
      "Left Shoulder: (525, 387), Right Shoulder: (201, 395)\n",
      "Left Shoulder: (521, 387), Right Shoulder: (197, 396)\n",
      "Left Shoulder: (519, 387), Right Shoulder: (198, 396)\n",
      "Left Shoulder: (514, 386), Right Shoulder: (197, 396)\n",
      "Left Shoulder: (513, 385), Right Shoulder: (197, 396)\n",
      "Left Shoulder: (510, 385), Right Shoulder: (196, 396)\n",
      "Left Shoulder: (509, 384), Right Shoulder: (195, 396)\n",
      "Left Shoulder: (507, 384), Right Shoulder: (195, 396)\n",
      "Left Shoulder: (506, 384), Right Shoulder: (193, 396)\n",
      "Left Shoulder: (506, 384), Right Shoulder: (192, 396)\n",
      "Left Shoulder: (507, 384), Right Shoulder: (192, 396)\n",
      "Left Shoulder: (507, 384), Right Shoulder: (192, 396)\n",
      "Left Shoulder: (509, 385), Right Shoulder: (192, 396)\n",
      "Left Shoulder: (510, 386), Right Shoulder: (192, 397)\n",
      "Left Shoulder: (511, 387), Right Shoulder: (193, 397)\n",
      "Left Shoulder: (512, 388), Right Shoulder: (193, 397)\n",
      "Left Shoulder: (512, 388), Right Shoulder: (193, 396)\n",
      "Left Shoulder: (512, 388), Right Shoulder: (193, 396)\n",
      "Left Shoulder: (513, 389), Right Shoulder: (193, 396)\n",
      "Left Shoulder: (516, 390), Right Shoulder: (194, 396)\n",
      "Left Shoulder: (517, 390), Right Shoulder: (194, 396)\n",
      "Left Shoulder: (519, 391), Right Shoulder: (195, 397)\n",
      "Left Shoulder: (521, 392), Right Shoulder: (195, 398)\n",
      "Left Shoulder: (523, 393), Right Shoulder: (195, 399)\n",
      "Left Shoulder: (523, 393), Right Shoulder: (195, 400)\n",
      "Left Shoulder: (523, 392), Right Shoulder: (195, 400)\n",
      "Left Shoulder: (522, 392), Right Shoulder: (195, 400)\n",
      "Left Shoulder: (522, 391), Right Shoulder: (195, 400)\n",
      "Left Shoulder: (523, 391), Right Shoulder: (197, 400)\n",
      "Left Shoulder: (523, 391), Right Shoulder: (198, 400)\n",
      "Left Shoulder: (523, 391), Right Shoulder: (198, 400)\n",
      "Left Shoulder: (523, 391), Right Shoulder: (199, 400)\n",
      "Left Shoulder: (523, 391), Right Shoulder: (199, 400)\n",
      "Left Shoulder: (523, 392), Right Shoulder: (200, 400)\n",
      "Left Shoulder: (523, 392), Right Shoulder: (201, 400)\n",
      "Left Shoulder: (524, 392), Right Shoulder: (201, 400)\n",
      "Left Shoulder: (524, 393), Right Shoulder: (202, 399)\n",
      "Left Shoulder: (525, 393), Right Shoulder: (202, 399)\n",
      "Left Shoulder: (525, 394), Right Shoulder: (201, 399)\n",
      "Left Shoulder: (525, 394), Right Shoulder: (202, 399)\n",
      "Left Shoulder: (525, 394), Right Shoulder: (202, 398)\n",
      "Left Shoulder: (525, 394), Right Shoulder: (202, 398)\n",
      "Left Shoulder: (525, 395), Right Shoulder: (201, 398)\n",
      "Left Shoulder: (525, 395), Right Shoulder: (201, 397)\n",
      "Left Shoulder: (525, 395), Right Shoulder: (201, 397)\n",
      "Left Shoulder: (525, 395), Right Shoulder: (201, 397)\n",
      "Left Shoulder: (526, 395), Right Shoulder: (201, 397)\n",
      "Left Shoulder: (526, 395), Right Shoulder: (201, 397)\n",
      "Left Shoulder: (526, 396), Right Shoulder: (202, 397)\n",
      "Left Shoulder: (526, 396), Right Shoulder: (202, 397)\n",
      "Left Shoulder: (526, 396), Right Shoulder: (201, 397)\n",
      "Left Shoulder: (526, 396), Right Shoulder: (201, 397)\n",
      "Left Shoulder: (525, 395), Right Shoulder: (201, 396)\n",
      "Left Shoulder: (525, 395), Right Shoulder: (201, 396)\n",
      "Left Shoulder: (524, 395), Right Shoulder: (201, 396)\n",
      "Left Shoulder: (524, 395), Right Shoulder: (201, 396)\n",
      "Left Shoulder: (524, 395), Right Shoulder: (201, 396)\n",
      "Left Shoulder: (524, 395), Right Shoulder: (200, 396)\n",
      "Left Shoulder: (525, 396), Right Shoulder: (200, 396)\n",
      "Left Shoulder: (525, 396), Right Shoulder: (200, 396)\n",
      "Left Shoulder: (525, 396), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (525, 396), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (524, 396), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (524, 396), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (523, 395), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (522, 395), Right Shoulder: (201, 397)\n",
      "Left Shoulder: (522, 395), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (521, 395), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (519, 395), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (519, 394), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (519, 394), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (519, 394), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (520, 394), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (520, 394), Right Shoulder: (201, 397)\n",
      "Left Shoulder: (520, 394), Right Shoulder: (201, 397)\n",
      "Left Shoulder: (521, 394), Right Shoulder: (202, 396)\n",
      "Left Shoulder: (521, 394), Right Shoulder: (202, 396)\n",
      "Left Shoulder: (521, 394), Right Shoulder: (202, 396)\n",
      "Left Shoulder: (521, 394), Right Shoulder: (202, 396)\n",
      "Left Shoulder: (521, 394), Right Shoulder: (202, 396)\n",
      "Left Shoulder: (521, 394), Right Shoulder: (202, 396)\n",
      "Left Shoulder: (521, 394), Right Shoulder: (202, 396)\n",
      "Left Shoulder: (521, 394), Right Shoulder: (202, 396)\n",
      "Left Shoulder: (521, 394), Right Shoulder: (202, 395)\n",
      "Left Shoulder: (521, 394), Right Shoulder: (202, 395)\n",
      "Left Shoulder: (522, 395), Right Shoulder: (203, 395)\n",
      "Left Shoulder: (522, 395), Right Shoulder: (203, 395)\n",
      "Left Shoulder: (522, 395), Right Shoulder: (204, 395)\n",
      "Left Shoulder: (522, 395), Right Shoulder: (205, 395)\n",
      "Left Shoulder: (523, 395), Right Shoulder: (205, 395)\n",
      "Left Shoulder: (524, 395), Right Shoulder: (205, 395)\n",
      "Left Shoulder: (524, 395), Right Shoulder: (205, 396)\n",
      "Left Shoulder: (523, 395), Right Shoulder: (204, 397)\n",
      "Left Shoulder: (523, 395), Right Shoulder: (203, 397)\n",
      "Left Shoulder: (523, 394), Right Shoulder: (203, 397)\n",
      "Left Shoulder: (522, 394), Right Shoulder: (202, 397)\n",
      "Left Shoulder: (522, 394), Right Shoulder: (202, 397)\n",
      "Left Shoulder: (521, 393), Right Shoulder: (201, 398)\n",
      "Left Shoulder: (521, 393), Right Shoulder: (199, 399)\n",
      "Left Shoulder: (520, 393), Right Shoulder: (198, 399)\n",
      "Left Shoulder: (520, 394), Right Shoulder: (198, 399)\n",
      "Left Shoulder: (520, 394), Right Shoulder: (196, 399)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (195, 400)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (195, 400)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (195, 399)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (194, 399)\n",
      "Left Shoulder: (519, 395), Right Shoulder: (194, 400)\n",
      "Left Shoulder: (519, 394), Right Shoulder: (194, 400)\n",
      "Left Shoulder: (519, 394), Right Shoulder: (194, 400)\n",
      "Left Shoulder: (519, 395), Right Shoulder: (194, 400)\n",
      "Left Shoulder: (519, 395), Right Shoulder: (194, 400)\n",
      "Left Shoulder: (519, 394), Right Shoulder: (194, 401)\n",
      "Left Shoulder: (519, 395), Right Shoulder: (194, 400)\n",
      "Left Shoulder: (519, 394), Right Shoulder: (194, 397)\n",
      "Left Shoulder: (518, 394), Right Shoulder: (194, 396)\n",
      "Left Shoulder: (518, 394), Right Shoulder: (195, 397)\n",
      "Left Shoulder: (518, 394), Right Shoulder: (195, 398)\n",
      "Left Shoulder: (518, 394), Right Shoulder: (196, 398)\n",
      "Left Shoulder: (519, 394), Right Shoulder: (197, 398)\n",
      "Left Shoulder: (520, 394), Right Shoulder: (198, 398)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (198, 398)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (199, 398)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (200, 398)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (200, 396)\n",
      "Left Shoulder: (520, 395), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (521, 395), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (521, 396), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (521, 396), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (521, 396), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (521, 396), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (521, 396), Right Shoulder: (200, 397)\n",
      "Left Shoulder: (521, 396), Right Shoulder: (201, 396)\n",
      "Left Shoulder: (521, 396), Right Shoulder: (201, 396)\n",
      "Left Shoulder: (521, 396), Right Shoulder: (201, 396)\n",
      "Left Shoulder: (521, 396), Right Shoulder: (201, 396)\n",
      "Left Shoulder: (521, 396), Right Shoulder: (201, 396)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    \n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m#get Pose landmarks\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m results = \u001b[43mpose\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Draw pose Landmarks\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m results.pose_landmarks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dewan\\Coding\\Python\\fito\\Lib\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001b[39m, in \u001b[36mPose.process\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np.ndarray) -> NamedTuple:\n\u001b[32m    165\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[32m    166\u001b[39m \n\u001b[32m    167\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m   results = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m results.pose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results.pose_landmarks.landmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dewan\\Coding\\Python\\fito\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:372\u001b[39m, in \u001b[36mSolutionBase.process\u001b[39m\u001b[34m(self, input_data)\u001b[39m\n\u001b[32m    366\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m._graph.add_packet_to_input_stream(\n\u001b[32m    368\u001b[39m         stream=stream_name,\n\u001b[32m    369\u001b[39m         packet=\u001b[38;5;28mself\u001b[39m._make_packet(input_stream_type,\n\u001b[32m    370\u001b[39m                                  data).at(\u001b[38;5;28mself\u001b[39m._simulated_timestamp))\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[32m    375\u001b[39m solution_outputs = collections.namedtuple(\n\u001b[32m    376\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mSolutionOutputs\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mself\u001b[39m._output_stream_type_info.keys())\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Start capturing video\n",
    "cap = cv2.VideoCapture(0) # Use 0 for webcam, or provide a video file path\n",
    "\n",
    "# Get video width, height, and FPS for saving\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define video writer to save the output\n",
    "out = cv2.VideoWriter('pose_output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened() :\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB (MediaPipe requires RGB format)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    \n",
    "\n",
    "    #get Pose landmarks\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "\n",
    "    # Draw pose Landmarks\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        #get shoulder coordinates\n",
    "        left_shoulder = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "        right_shoulder = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "\n",
    "        # Convert normalized coordinates (0-1) to pixel values\n",
    "        left_shoulder_x,left_shoulder_y = int(left_shoulder.x * frame_width) , int(left_shoulder.y * frame_height)\n",
    "        right_shoulder_x,right_shoulder_y = int(right_shoulder.x * frame_width) , int(right_shoulder.y * frame_height)\n",
    "        \n",
    "        # print coordinates\n",
    "        print(f\"Left Shoulder: ({left_shoulder_x}, {left_shoulder_y}), Right Shoulder: ({right_shoulder_x}, {right_shoulder_y})\")\n",
    "\n",
    "        # Draw Circles on Shoulders\n",
    "        cv2.circle(frame,(left_shoulder_x,left_shoulder_y), 5,(0,255,0),-1)\n",
    "        cv2.circle(frame,(right_shoulder_x,right_shoulder_y), 5,(0,255,0),-1)\n",
    "\n",
    "    # Save video Frame\n",
    "    out.write(frame)\n",
    "\n",
    "    #show output\n",
    "    cv2.imshow(\"Pose Detection\",frame)\n",
    "\n",
    "\n",
    "    #press q tp quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Step 5: Measure Angle Between Joints (Shoulder, Elbow, Wrist)\n",
    "\n",
    "#### Now that we can track the shoulders, let‚Äôs calculate the angle between joints to evaluate form. This is useful for checking exercise posture like bicep curls, squats, or push-ups.\n",
    "## üî¢ How to Calculate the Angle?\n",
    "\n",
    "We use the cosine rule:\n",
    "Œ∏=cos‚Å°‚àí1(b2+c2‚àía22bc)\n",
    "Œ∏=cos‚àí1(2bcb2+c2‚àía2‚Äã)\n",
    "\n",
    "where:\n",
    "\n",
    "    a, b, c are the distances between points.\n",
    "    Œ∏ is the joint angle (in degrees).\n",
    "\n",
    "We'll calculate elbow flexion angle using:\n",
    "\n",
    "    Shoulder\n",
    "    Elbow\n",
    "    Wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'landmark'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m results.pose_landmarks:\n\u001b[32m     45\u001b[39m     mp_drawing.draw_landmarks(frame,results.pose_landmarks,mp_pose.POSE_CONNECTIONS)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m landmarks = \u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpose_landmarks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlandmark\u001b[49m\n\u001b[32m     49\u001b[39m shoulder = (\u001b[38;5;28mint\u001b[39m(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x * frame_width),\n\u001b[32m     50\u001b[39m             \u001b[38;5;28mint\u001b[39m(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y * frame_height))\n\u001b[32m     52\u001b[39m elbow = (\u001b[38;5;28mint\u001b[39m(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].x * frame_width),\n\u001b[32m     53\u001b[39m             \u001b[38;5;28mint\u001b[39m(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].y * frame_height))\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'landmark'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "#start capturing video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def calculate_angles(a,b,c):\n",
    "\n",
    "    a = np.array(a) #first point\n",
    "    b = np.array(b) # mid Point (joint)\n",
    "    c = np.array(c) # last point\n",
    "\n",
    "    # Calculate vectors\n",
    "    ba = a - b\n",
    "    bc = c-b\n",
    "\n",
    "    # Compute cosine of the angle\n",
    "    cosine_angle = np.dot(ba,bc) / ( np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "\n",
    "    #convert to degrees\n",
    "    angle = np.degrees(np.arccos(cosine_angle))\n",
    "\n",
    "    return angle\n",
    "\n",
    "while cap.isOpened() :\n",
    "    ret ,frame = cap.read()\n",
    "    \n",
    "    if not ret :\n",
    "        break\n",
    "\n",
    "    frame_height,frame_width , _ = frame.shape\n",
    "\n",
    "    #convert to rgb\n",
    "    rgb_frame = cv2.cvtColor(frame , cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame,results.pose_landmarks,mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "    shoulder = (int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x * frame_width),\n",
    "                int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y * frame_height))\n",
    "\n",
    "    elbow = (int(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].x * frame_width),\n",
    "                int(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].y * frame_height))\n",
    "\n",
    "    wrist = (int(landmarks[mp_pose.PoseLandmark.LEFT_WRIST].x * frame_width),\n",
    "                int(landmarks[mp_pose.PoseLandmark.LEFT_WRIST].y * frame_height))\n",
    "\n",
    "    angle = calculate_angles(shoulder , elbow , wrist)\n",
    "\n",
    "\n",
    "    cv2.putText(frame, f\"Angle: {int(angle)} deg\", (elbow[0] - 50, elbow[1] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    cv2.circle(frame, shoulder, 5, (255, 0, 0), -1)\n",
    "    cv2.circle(frame, elbow, 5, (0, 255, 0), -1)\n",
    "    cv2.circle(frame, wrist, 5, (0, 0, 255), -1)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Pose Detection with Angle calculation\" , frame)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• Next Steps: Adding Rep Counting!\n",
    "\n",
    "#### Now that we detect arm angles, we can count reps for an exercise like bicep curls using a simple threshold-based approach.\n",
    "### üõ† Plan for Rep Counting:\n",
    "\n",
    "#### 1Ô∏è‚É£ Detect Curl Motion: Track elbow angle\n",
    "#### 2Ô∏è‚É£ Set Thresholds:\n",
    "\n",
    "    Top Position: Arm is straight (angle ~160¬∞-180¬∞)\n",
    "    Bottom Position: Arm is bent (angle ~30¬∞-60¬∞)\n",
    "    3Ô∏è‚É£ Count Reps:\n",
    "    A rep is counted when the arm moves from top to bottom and back up\n",
    "    Use a state machine to avoid counting multiple times\n",
    "    4Ô∏è‚É£ Show Reps on Screen üéØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.42.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\dewan\\coding\\python\\fito\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\dewan\\coding\\python\\fito\\lib\\site-packages (from streamlit) (24.2)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\dewan\\coding\\python\\fito\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\dewan\\coding\\python\\fito\\lib\\site-packages (from streamlit) (3.20.3)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-19.0.1-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting requests<3,>=2.27 (from streamlit)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\dewan\\coding\\python\\fito\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Using cached watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\dewan\\coding\\python\\fito\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Collecting jinja2 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.28.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dewan\\coding\\python\\fito\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dewan\\coding\\python\\fito\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.27->streamlit)\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.27->streamlit)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.27->streamlit)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.27->streamlit)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dewan\\coding\\python\\fito\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.19.1)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->altair<6,>=4.0->streamlit)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\dewan\\coding\\python\\fito\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.23.1-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dewan\\coding\\python\\fito\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit-1.42.2-py2.py3-none-any.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 3.1/9.6 MB 20.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.5/9.6 MB 17.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.6 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.6 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 11.7 MB/s eta 0:00:00\n",
      "Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 3.7/11.6 MB 19.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.0/11.6 MB 11.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.9/11.6 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.6 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading pyarrow-19.0.1-cp311-cp311-win_amd64.whl (25.3 MB)\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 3.9/25.3 MB 21.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.8/25.3 MB 16.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.7/25.3 MB 15.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.3/25.3 MB 14.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 14.9/25.3 MB 14.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.8/25.3 MB 14.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 20.4/25.3 MB 14.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.1/25.3 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.3 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.3/25.3 MB 13.0 MB/s eta 0:00:00\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading narwhals-1.28.0-py3-none-any.whl (308 kB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.23.1-cp311-cp311-win_amd64.whl (232 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pytz, watchdog, urllib3, tzdata, toml, tenacity, smmap, rpds-py, pyarrow, narwhals, mdurl, MarkupSafe, idna, click, charset-normalizer, certifi, cachetools, blinker, requests, referencing, pandas, markdown-it-py, jinja2, gitdb, rich, pydeck, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "Successfully installed MarkupSafe-3.0.2 altair-5.5.0 blinker-1.9.0 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 gitdb-4.0.12 gitpython-3.1.44 idna-3.10 jinja2-3.1.5 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 markdown-it-py-3.0.0 mdurl-0.1.2 narwhals-1.28.0 pandas-2.2.3 pyarrow-19.0.1 pydeck-0.9.1 pytz-2025.1 referencing-0.36.2 requests-2.32.3 rich-13.9.4 rpds-py-0.23.1 smmap-5.0.2 streamlit-1.42.2 tenacity-9.0.0 toml-0.10.2 tzdata-2025.1 urllib3-2.3.0 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-6.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\dewan\\coding\\python\\fito\\lib\\site-packages (from plotly) (1.28.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dewan\\coding\\python\\fito\\lib\\site-packages (from plotly) (24.2)\n",
      "Downloading plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
      "   ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 3.1/14.8 MB 23.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.5/14.8 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.9/14.8 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.2/14.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.7/14.8 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/14.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.8/14.8 MB 11.8 MB/s eta 0:00:00\n",
      "Installing collected packages: plotly\n",
      "Successfully installed plotly-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 23:39:34.688 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-01 23:39:35.267 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\dewan\\Coding\\Python\\fito\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-01 23:39:35.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-01 23:39:35.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-01 23:39:35.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-01 23:39:35.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-01 23:39:35.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-01 23:39:35.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-01 23:39:35.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-01 23:39:35.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-01 23:39:35.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-01 23:39:35.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-01 23:39:35.268 Session state does not function when running a script without `streamlit run`\n",
      "2025-03-01 23:39:35.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-01 23:39:35.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Initialize Pose Model\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.degrees(np.arccos(cosine_angle))\n",
    "    return angle\n",
    "\n",
    "# Function for counting reps\n",
    "def count_reps(angles, threshold_down=160, threshold_up=50):\n",
    "    count = 0\n",
    "    direction = 0  # 0: neutral, 1: going down, 2: going up\n",
    "    \n",
    "    for angle in angles:\n",
    "        if angle > threshold_down:\n",
    "            if direction == 2:\n",
    "                count += 1\n",
    "                direction = 0\n",
    "        elif angle < threshold_up:\n",
    "            direction = 2\n",
    "        else:\n",
    "            direction = 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "# Function for Pose Detection & Rep Counting\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "    angles_list = []\n",
    "    skeleton_points = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb_frame)\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            shoulder = (int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x * frame_width),\n",
    "                        int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y * frame_height))\n",
    "            elbow = (int(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].x * frame_width),\n",
    "                     int(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].y * frame_height))\n",
    "            wrist = (int(landmarks[mp_pose.PoseLandmark.LEFT_WRIST].x * frame_width),\n",
    "                     int(landmarks[mp_pose.PoseLandmark.LEFT_WRIST].y * frame_height))\n",
    "            \n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            angles_list.append(angle)\n",
    "            \n",
    "            skeleton_points.append([\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x, \n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y, \n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].z\n",
    "            ])\n",
    "            \n",
    "            cv2.putText(frame, f'Angle: {int(angle)}', (elbow[0] - 50, elbow[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.circle(frame, shoulder, 5, (255, 0, 0), -1)\n",
    "            cv2.circle(frame, elbow, 5, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, wrist, 5, (0, 0, 255), -1)\n",
    "        \n",
    "        out.write(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    reps = count_reps(angles_list)\n",
    "    return 'output.mp4', reps, skeleton_points\n",
    "\n",
    "# Function to generate 3D visualization\n",
    "def generate_3d_pose(skeleton_points):\n",
    "    fig = go.Figure()\n",
    "    x, y, z = zip(*skeleton_points)\n",
    "    \n",
    "    fig.add_trace(go.Scatter3d(x=x, y=y, z=z, mode='markers+lines', marker=dict(size=5, color='blue')))\n",
    "    fig.update_layout(scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'), title='3D Pose Visualization')\n",
    "    return fig\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"AI Fitness Coach - Pose Estimation, Rep Counter & 3D Visualization\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload an exercise video\", type=[\"mp4\", \"mov\", \"avi\"])\n",
    "view_option = st.radio(\"Select View Mode:\", [\"Skeleton (Lines)\", \"3D Muscle Body\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "        temp_file.write(uploaded_file.read())\n",
    "        video_path = temp_file.name\n",
    "    \n",
    "    st.video(video_path)\n",
    "    st.write(\"Processing video...\")\n",
    "    \n",
    "    output_video_path, rep_count, skeleton_points = process_video(video_path)\n",
    "    \n",
    "    st.video(output_video_path)\n",
    "    st.success(f\"Processing Complete! Total Reps Counted: {rep_count}\")\n",
    "    \n",
    "    if view_option == \"Skeleton (Lines)\":\n",
    "        st.plotly_chart(generate_3d_pose(skeleton_points))\n",
    "    else:\n",
    "        st.write(\"3D Muscle Body Visualization (Coming Soon)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Initialize Pose Model\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.degrees(np.arccos(cosine_angle))\n",
    "    return angle\n",
    "\n",
    "# Function for counting reps\n",
    "def count_reps(angles, threshold_down=160, threshold_up=50):\n",
    "    count = 0\n",
    "    direction = 0  # 0: neutral, 1: going down, 2: going up\n",
    "    \n",
    "    for angle in angles:\n",
    "        if angle > threshold_down:\n",
    "            if direction == 2:\n",
    "                count += 1\n",
    "                direction = 0\n",
    "        elif angle < threshold_up:\n",
    "            direction = 2\n",
    "        else:\n",
    "            direction = 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "# Function for Real-time Pose Detection & Rep Counting\n",
    "def live_tracking():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    angles_list = []\n",
    "    skeleton_points = []\n",
    "    peak_concentration = 0\n",
    "    \n",
    "    cv2.namedWindow(\"Live Pose Tracking\", cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty(\"Live Pose Tracking\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb_frame)\n",
    "        \n",
    "        try:\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "                \n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                \n",
    "                joints = {\n",
    "                    'left_shoulder': (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),\n",
    "                    'right_shoulder': (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST)\n",
    "                }\n",
    "                \n",
    "                for side, (shoulder_idx, elbow_idx, wrist_idx) in joints.items():\n",
    "                    shoulder = (int(landmarks[shoulder_idx].x * frame_width),\n",
    "                                int(landmarks[shoulder_idx].y * frame_height))\n",
    "                    elbow = (int(landmarks[elbow_idx].x * frame_width),\n",
    "                             int(landmarks[elbow_idx].y * frame_height))\n",
    "                    wrist = (int(landmarks[wrist_idx].x * frame_width),\n",
    "                             int(landmarks[wrist_idx].y * frame_height))\n",
    "                    \n",
    "                    angle = calculate_angle(shoulder, elbow, wrist)\n",
    "                    angles_list.append(angle)\n",
    "                    \n",
    "                    skeleton_points.append([\n",
    "                        landmarks[shoulder_idx].x, \n",
    "                        landmarks[shoulder_idx].y, \n",
    "                        landmarks[shoulder_idx].z\n",
    "                    ])\n",
    "                    \n",
    "                    cv2.putText(frame, f'{side.capitalize()} Angle: {int(angle)}', (elbow[0] - 50, elbow[1] - 20), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                    \n",
    "                    cv2.circle(frame, shoulder, 5, (255, 0, 0), -1)\n",
    "                    cv2.circle(frame, elbow, 5, (0, 255, 0), -1)\n",
    "                    cv2.circle(frame, wrist, 5, (0, 0, 255), -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing landmarks: {e}\")\n",
    "        \n",
    "        # Display muscle concentration bar\n",
    "        muscle_concentration = angles_list[-1] if angles_list else 0  # Use the latest angle for faster response\n",
    "        peak_concentration = min(peak_concentration, muscle_concentration)\n",
    "        bar_length = int(muscle_concentration / 180 * 200)  # Scale for visualization\n",
    "        cv2.rectangle(frame, (50, 50), (50 + bar_length, 70), (0, 255, 0), -1)\n",
    "        cv2.putText(frame, f'Muscle Concentration: {int(muscle_concentration)}%', (50, 45), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        # Display peak concentration\n",
    "        cv2.putText(frame, f'Peak Concentration: {int(peak_concentration)}%', (50, 90), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow(\"Live Pose Tracking\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    reps = count_reps(angles_list)\n",
    "    return reps, skeleton_points\n",
    "\n",
    "# Function to generate 3D visualization\n",
    "def generate_3d_pose(skeleton_points):\n",
    "    fig = go.Figure()\n",
    "    x, y, z = zip(*skeleton_points)\n",
    "    \n",
    "    fig.add_trace(go.Scatter3d(x=x, y=y, z=z, mode='markers+lines', marker=dict(size=5, color='blue')))\n",
    "    fig.update_layout(scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'), title='3D Pose Visualization')\n",
    "    return fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    live_tracking()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing landmarks: cannot convert float NaN to integer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dewan\\AppData\\Local\\Temp\\ipykernel_22700\\3726280665.py:21: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.degrees(np.arccos(cosine_angle))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 150\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fig\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[43mlive_tracking\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 112\u001b[39m, in \u001b[36mlive_tracking\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    109\u001b[39m right_peak_concentration = \u001b[38;5;28mmax\u001b[39m(right_peak_concentration, right_concentration)\n\u001b[32m    111\u001b[39m left_bar_length = \u001b[38;5;28mint\u001b[39m(left_concentration / \u001b[32m180\u001b[39m * \u001b[32m200\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m right_bar_length = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mright_concentration\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m180\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m cv2.rectangle(frame, (\u001b[32m50\u001b[39m, \u001b[32m50\u001b[39m), (\u001b[32m50\u001b[39m + left_bar_length, \u001b[32m70\u001b[39m), (\u001b[32m0\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m    115\u001b[39m cv2.putText(frame, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLeft Concentration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(left_concentration)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m'\u001b[39m, (\u001b[32m50\u001b[39m, \u001b[32m45\u001b[39m), \n\u001b[32m    116\u001b[39m             cv2.FONT_HERSHEY_SIMPLEX, \u001b[32m0.5\u001b[39m, (\u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m), \u001b[32m2\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: cannot convert float NaN to integer"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Initialize Pose Model\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.degrees(np.arccos(cosine_angle))\n",
    "    return angle\n",
    "\n",
    "# Function for counting reps\n",
    "def count_reps(angles, threshold_down=160, threshold_up=50):\n",
    "    count = 0\n",
    "    direction = 0  # 0: neutral, 1: going down, 2: going up\n",
    "    \n",
    "    for angle in angles:\n",
    "        if angle > threshold_down:\n",
    "            if direction == 2:\n",
    "                count += 1\n",
    "                direction = 0\n",
    "        elif angle < threshold_up:\n",
    "            direction = 2\n",
    "        else:\n",
    "            direction = 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "# Function for Real-time Pose Detection & Rep Counting\n",
    "def live_tracking():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    left_angles = []\n",
    "    right_angles = []\n",
    "    skeleton_points = []\n",
    "    left_peak_concentration = 0\n",
    "    right_peak_concentration = 0\n",
    "    \n",
    "    cv2.namedWindow(\"Live Pose Tracking\", cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty(\"Live Pose Tracking\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb_frame)\n",
    "        \n",
    "        try:\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "                \n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                \n",
    "                joints = {\n",
    "                    'left': (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),\n",
    "                    'right': (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST)\n",
    "                }\n",
    "                \n",
    "                for side, (shoulder_idx, elbow_idx, wrist_idx) in joints.items():\n",
    "                    shoulder = (int(landmarks[shoulder_idx].x * frame_width),\n",
    "                                int(landmarks[shoulder_idx].y * frame_height))\n",
    "                    elbow = (int(landmarks[elbow_idx].x * frame_width),\n",
    "                             int(landmarks[elbow_idx].y * frame_height))\n",
    "                    wrist = (int(landmarks[wrist_idx].x * frame_width),\n",
    "                             int(landmarks[wrist_idx].y * frame_height))\n",
    "                    \n",
    "                    angle = calculate_angle(shoulder, elbow, wrist)\n",
    "                    if side == 'left':\n",
    "                        left_angles.append(angle)\n",
    "                    else:\n",
    "                        right_angles.append(angle)\n",
    "                    \n",
    "                    skeleton_points.append([\n",
    "                        landmarks[shoulder_idx].x, \n",
    "                        landmarks[shoulder_idx].y, \n",
    "                        landmarks[shoulder_idx].z\n",
    "                    ])\n",
    "                    \n",
    "                    cv2.putText(frame, f'{side.capitalize()} Angle: {int(angle)}', (elbow[0] - 50, elbow[1] - 20), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                    \n",
    "                    cv2.circle(frame, shoulder, 5, (255, 0, 0), -1)\n",
    "                    cv2.circle(frame, elbow, 5, (0, 255, 0), -1)\n",
    "                    cv2.circle(frame, wrist, 5, (0, 0, 255), -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing landmarks: {e}\")\n",
    "        \n",
    "        # Display muscle concentration bars\n",
    "        left_concentration = left_angles[-1] if left_angles else 0\n",
    "        right_concentration = right_angles[-1] if right_angles else 0\n",
    "        \n",
    "        left_peak_concentration = max(left_peak_concentration, left_concentration)\n",
    "        right_peak_concentration = max(right_peak_concentration, right_concentration)\n",
    "        \n",
    "        left_bar_length = int(left_concentration / 180 * 200)\n",
    "        right_bar_length = int(right_concentration / 180 * 200)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 50), (50 + left_bar_length, 70), (0, 255, 0), -1)\n",
    "        cv2.putText(frame, f'Left Concentration: {int(left_concentration)}%', (50, 45), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 100), (50 + right_bar_length, 120), (255, 0, 0), -1)\n",
    "        cv2.putText(frame, f'Right Concentration: {int(right_concentration)}%', (50, 95), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        # Display peak concentrations\n",
    "        cv2.putText(frame, f'Left Peak: {int(left_peak_concentration)}%', (50, 140), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, f'Right Peak: {int(right_peak_concentration)}%', (50, 160), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow(\"Live Pose Tracking\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    left_reps = count_reps(left_angles)\n",
    "    right_reps = count_reps(right_angles)\n",
    "    return left_reps, right_reps, skeleton_points\n",
    "\n",
    "# Function to generate 3D visualization\n",
    "def generate_3d_pose(skeleton_points):\n",
    "    fig = go.Figure()\n",
    "    x, y, z = zip(*skeleton_points)\n",
    "    \n",
    "    fig.add_trace(go.Scatter3d(x=x, y=y, z=z, mode='markers+lines', marker=dict(size=5, color='blue')))\n",
    "    fig.update_layout(scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'), title='3D Pose Visualization')\n",
    "    return fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    live_tracking()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Initialize Pose Model\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))  # Ensure valid range\n",
    "    return angle\n",
    "\n",
    "# Function for counting reps\n",
    "def count_reps(angles, threshold_down=160, threshold_up=50):\n",
    "    count = 0\n",
    "    direction = 0  # 0: neutral, 1: going down, 2: going up\n",
    "    \n",
    "    for angle in angles:\n",
    "        if angle > threshold_down:\n",
    "            if direction == 2:\n",
    "                count += 1\n",
    "                direction = 0\n",
    "        elif angle < threshold_up:\n",
    "            direction = 2\n",
    "        else:\n",
    "            direction = 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "# Function for Real-time Pose Detection & Rep Counting\n",
    "def live_tracking():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    left_angles = []\n",
    "    right_angles = []\n",
    "    skeleton_points = []\n",
    "    left_peak_concentration = 0\n",
    "    right_peak_concentration = 0\n",
    "    \n",
    "    cv2.namedWindow(\"Live Pose Tracking\", cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty(\"Live Pose Tracking\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb_frame)\n",
    "        \n",
    "        try:\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "                \n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                \n",
    "                joints = {\n",
    "                    'left': (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),\n",
    "                    'right': (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST)\n",
    "                }\n",
    "                \n",
    "                for side, (shoulder_idx, elbow_idx, wrist_idx) in joints.items():\n",
    "                    shoulder = (int(landmarks[shoulder_idx].x * frame_width),\n",
    "                                int(landmarks[shoulder_idx].y * frame_height))\n",
    "                    elbow = (int(landmarks[elbow_idx].x * frame_width),\n",
    "                             int(landmarks[elbow_idx].y * frame_height))\n",
    "                    wrist = (int(landmarks[wrist_idx].x * frame_width),\n",
    "                             int(landmarks[wrist_idx].y * frame_height))\n",
    "                    \n",
    "                    angle = calculate_angle(shoulder, elbow, wrist)\n",
    "                    angle = min(angle, 180)  # Normalize angle range\n",
    "                    \n",
    "                    if side == 'left':\n",
    "                        left_angles.append(angle)\n",
    "                    else:\n",
    "                        right_angles.append(angle)\n",
    "                    \n",
    "                    skeleton_points.append([\n",
    "                        landmarks[shoulder_idx].x, \n",
    "                        landmarks[shoulder_idx].y, \n",
    "                        landmarks[shoulder_idx].z\n",
    "                    ])\n",
    "                    \n",
    "                    cv2.putText(frame, f'{side.capitalize()} Angle: {int(angle)}', (elbow[0] - 50, elbow[1] - 20), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                    \n",
    "                    cv2.circle(frame, shoulder, 5, (255, 0, 0), -1)\n",
    "                    cv2.circle(frame, elbow, 5, (0, 255, 0), -1)\n",
    "                    cv2.circle(frame, wrist, 5, (0, 0, 255), -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing landmarks: {e}\")\n",
    "        \n",
    "        # Display muscle concentration bars\n",
    "        left_concentration = left_angles[-1] if left_angles else 0\n",
    "        right_concentration = right_angles[-1] if right_angles else 0\n",
    "        \n",
    "        left_peak_concentration = max(left_peak_concentration, left_concentration)\n",
    "        right_peak_concentration = max(right_peak_concentration, right_concentration)\n",
    "        \n",
    "        left_bar_length = int(left_concentration / 180 * 200)\n",
    "        right_bar_length = int(right_concentration / 180 * 200)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 50), (50 + left_bar_length, 70), (0, 255, 0), -1)\n",
    "        cv2.putText(frame, f'Left Concentration: {int(left_concentration)}%', (50, 45), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 100), (50 + right_bar_length, 120), (255, 0, 0), -1)\n",
    "        cv2.putText(frame, f'Right Concentration: {int(right_concentration)}%', (50, 95), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        # Display peak concentrations\n",
    "        cv2.putText(frame, f'Left Peak: {int(left_peak_concentration)}%', (50, 140), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, f'Right Peak: {int(right_peak_concentration)}%', (50, 160), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow(\"Live Pose Tracking\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    left_reps = count_reps(left_angles)\n",
    "    right_reps = count_reps(right_angles)\n",
    "    return left_reps, right_reps, skeleton_points\n",
    "\n",
    "# Function to generate 3D visualization\n",
    "def generate_3d_pose(skeleton_points):\n",
    "    fig = go.Figure()\n",
    "    x, y, z = zip(*skeleton_points)\n",
    "    \n",
    "    fig.add_trace(go.Scatter3d(x=x, y=y, z=z, mode='markers+lines', marker=dict(size=5, color='blue')))\n",
    "    fig.update_layout(scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'), title='3D Pose Visualization')\n",
    "    return fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    live_tracking()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Pose Model\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))  # Ensure valid range\n",
    "    return angle\n",
    "\n",
    "# Function for Real-time Pose Detection & Rep Counting\n",
    "def live_tracking():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    left_angles = []\n",
    "    right_angles = []\n",
    "    left_peak_concentration = 0\n",
    "    right_peak_concentration = 0\n",
    "    \n",
    "    cv2.namedWindow(\"Live Pose Tracking\", cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty(\"Live Pose Tracking\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb_frame)\n",
    "        \n",
    "        try:\n",
    "            results.pose_landmarks.landmark  # Attempt to access landmarks\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            joints = {\n",
    "                'left': (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),\n",
    "                'right': (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST)\n",
    "            }\n",
    "            \n",
    "            for side, (shoulder_idx, elbow_idx, wrist_idx) in joints.items():\n",
    "                shoulder = (int(landmarks[shoulder_idx].x * frame_width),\n",
    "                            int(landmarks[shoulder_idx].y * frame_height))\n",
    "                elbow = (int(landmarks[elbow_idx].x * frame_width),\n",
    "                         int(landmarks[elbow_idx].y * frame_height))\n",
    "                wrist = (int(landmarks[wrist_idx].x * frame_width),\n",
    "                         int(landmarks[wrist_idx].y * frame_height))\n",
    "                \n",
    "                angle = calculate_angle(shoulder, elbow, wrist)\n",
    "                angle = min(angle, 180)  # Normalize angle range\n",
    "                \n",
    "                if side == 'left':\n",
    "                    left_angles.append(angle)\n",
    "                else:\n",
    "                    right_angles.append(angle)\n",
    "                \n",
    "                cv2.putText(frame, f'{side.capitalize()} Angle: {int(angle)}', (elbow[0] - 50, elbow[1] - 20), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                \n",
    "                cv2.circle(frame, shoulder, 5, (255, 0, 0), -1)\n",
    "                cv2.circle(frame, elbow, 5, (0, 255, 0), -1)\n",
    "                cv2.circle(frame, wrist, 5, (0, 0, 255), -1)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Display muscle concentration bars based on peak at 30-degree angle\n",
    "        left_concentration = max(0, 100 - abs(left_angles[-1] - 30)) if left_angles else 0\n",
    "        right_concentration = max(0, 100 - abs(right_angles[-1] - 30)) if right_angles else 0\n",
    "        \n",
    "        left_peak_concentration = max(left_peak_concentration, left_concentration)\n",
    "        right_peak_concentration = max(right_peak_concentration, right_concentration)\n",
    "        \n",
    "        left_bar_length = int(left_concentration)\n",
    "        right_bar_length = int(right_concentration)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 50), (50 + left_bar_length * 2, 70), (0, 255, 0), -1)\n",
    "        cv2.putText(frame, f'Left Concentration: {int(left_concentration)}%', (50, 45), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 100), (50 + right_bar_length * 2, 120), (255, 0, 0), -1)\n",
    "        cv2.putText(frame, f'Right Concentration: {int(right_concentration)}%', (50, 95), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow(\"Live Pose Tracking\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    live_tracking()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Pose Model\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))  # Ensure valid range\n",
    "    return angle\n",
    "\n",
    "# Function for Real-time Pose Detection & Rep Counting\n",
    "def live_tracking():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    left_angles = []\n",
    "    right_angles = []\n",
    "    left_peak_concentration = 0\n",
    "    right_peak_concentration = 0\n",
    "    \n",
    "    cv2.namedWindow(\"Live Pose Tracking\", cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty(\"Live Pose Tracking\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb_frame)\n",
    "        \n",
    "        if results.pose_landmarks and results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].visibility > 0.6:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            joints = {\n",
    "                'left': (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),\n",
    "                'right': (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST)\n",
    "            }\n",
    "            \n",
    "            for side, (shoulder_idx, elbow_idx, wrist_idx) in joints.items():\n",
    "                shoulder = (int(landmarks[shoulder_idx].x * frame_width),\n",
    "                            int(landmarks[shoulder_idx].y * frame_height))\n",
    "                elbow = (int(landmarks[elbow_idx].x * frame_width),\n",
    "                         int(landmarks[elbow_idx].y * frame_height))\n",
    "                wrist = (int(landmarks[wrist_idx].x * frame_width),\n",
    "                         int(landmarks[wrist_idx].y * frame_height))\n",
    "                \n",
    "                angle = calculate_angle(shoulder, elbow, wrist)\n",
    "                angle = min(angle, 180)  # Normalize angle range\n",
    "                \n",
    "                if side == 'left':\n",
    "                    left_angles.append(angle)\n",
    "                else:\n",
    "                    right_angles.append(angle)\n",
    "                \n",
    "                cv2.putText(frame, f'{side.capitalize()} Angle: {int(angle)}', (elbow[0] - 50, elbow[1] - 20), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                \n",
    "                cv2.circle(frame, shoulder, 5, (255, 0, 0), -1)\n",
    "                cv2.circle(frame, elbow, 5, (0, 255, 0), -1)\n",
    "                cv2.circle(frame, wrist, 5, (0, 0, 255), -1)\n",
    "        \n",
    "        # Display muscle concentration bars based on peak at 30-degree angle\n",
    "        left_concentration = max(0, 100 - abs(left_angles[-1] - 30)) if left_angles else 0\n",
    "        right_concentration = max(0, 100 - abs(right_angles[-1] - 30)) if right_angles else 0\n",
    "        \n",
    "        left_peak_concentration = max(left_peak_concentration, left_concentration)\n",
    "        right_peak_concentration = max(right_peak_concentration, right_concentration)\n",
    "        \n",
    "        left_bar_length = int(left_concentration)\n",
    "        right_bar_length = int(right_concentration)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 50), (50 + left_bar_length * 2, 70), (0, 255, 0), -1)\n",
    "        cv2.putText(frame, f'Left Concentration: {int(left_concentration)}%', (50, 45), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 100), (50 + right_bar_length * 2, 120), (255, 0, 0), -1)\n",
    "        cv2.putText(frame, f'Right Concentration: {int(right_concentration)}%', (50, 95), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow(\"Live Pose Tracking\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    live_tracking()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dewan\\AppData\\Local\\Temp\\ipykernel_22168\\1964957081.py:19: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Pose Model\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))  # Ensure valid range\n",
    "    return angle\n",
    "\n",
    "# Function for Real-time Pose Detection & Rep Counting\n",
    "def live_tracking():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    left_angles = []\n",
    "    right_angles = []\n",
    "    left_peak_concentration = 0\n",
    "    right_peak_concentration = 0\n",
    "    \n",
    "    cv2.namedWindow(\"Live Pose Tracking\", cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty(\"Live Pose Tracking\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb_frame)\n",
    "        \n",
    "        try:\n",
    "            if results.pose_landmarks and results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].visibility > 0.6:\n",
    "                mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "                \n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                \n",
    "                joints = {\n",
    "                    'left': (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),\n",
    "                    'right': (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST)\n",
    "                }\n",
    "                \n",
    "                for side, (shoulder_idx, elbow_idx, wrist_idx) in joints.items():\n",
    "                    shoulder = (int(landmarks[shoulder_idx].x * frame_width),\n",
    "                                int(landmarks[shoulder_idx].y * frame_height))\n",
    "                    elbow = (int(landmarks[elbow_idx].x * frame_width),\n",
    "                             int(landmarks[elbow_idx].y * frame_height))\n",
    "                    wrist = (int(landmarks[wrist_idx].x * frame_width),\n",
    "                             int(landmarks[wrist_idx].y * frame_height))\n",
    "                    \n",
    "                    angle = calculate_angle(shoulder, elbow, wrist)\n",
    "                    angle = min(angle, 180)  # Normalize angle range\n",
    "                    \n",
    "                    if side == 'left':\n",
    "                        left_angles.append(angle)\n",
    "                    else:\n",
    "                        right_angles.append(angle)\n",
    "                    \n",
    "                    cv2.putText(frame, f'{side.capitalize()} Angle: {int(angle)}', (elbow[0] - 50, elbow[1] - 20), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                    \n",
    "                    cv2.circle(frame, shoulder, 5, (255, 0, 0), -1)\n",
    "                    cv2.circle(frame, elbow, 5, (0, 255, 0), -1)\n",
    "                    cv2.circle(frame, wrist, 5, (0, 0, 255), -1)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "        # Display muscle concentration bars based on peak at 30-degree angle\n",
    "        left_concentration = max(0, 100 - abs(left_angles[-1] - 30)) if left_angles else 0\n",
    "        right_concentration = max(0, 100 - abs(right_angles[-1] - 30)) if right_angles else 0\n",
    "        \n",
    "        left_peak_concentration = max(left_peak_concentration, left_concentration)\n",
    "        right_peak_concentration = max(right_peak_concentration, right_concentration)\n",
    "        \n",
    "        left_bar_length = int(left_concentration)\n",
    "        right_bar_length = int(right_concentration)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 50), (50 + left_bar_length * 2, 70), (0, 255, 0), -1)\n",
    "        cv2.putText(frame, f'Left Concentration: {int(left_concentration)}%', (50, 45), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 100), (50 + right_bar_length * 2, 120), (255, 0, 0), -1)\n",
    "        cv2.putText(frame, f'Right Concentration: {int(right_concentration)}%', (50, 95), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow(\"Live Pose Tracking\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    live_tracking()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Pose Model\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))  # Ensure valid range\n",
    "    return angle\n",
    "\n",
    "# Function for Real-time Pose Detection & Rep Counting\n",
    "def live_tracking():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    left_angles = []\n",
    "    right_angles = []\n",
    "    left_peak_concentration = 0\n",
    "    right_peak_concentration = 0\n",
    "    \n",
    "    cv2.namedWindow(\"Live Pose Tracking\", cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty(\"Live Pose Tracking\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb_frame)\n",
    "        \n",
    "        try:\n",
    "            if results.pose_landmarks and results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].visibility > 0.6:\n",
    "                mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "                \n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                \n",
    "                joints = {\n",
    "                    'left': (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),\n",
    "                    'right': (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST)\n",
    "                }\n",
    "                \n",
    "                for side, (shoulder_idx, elbow_idx, wrist_idx) in joints.items():\n",
    "                    if (landmarks[shoulder_idx].visibility > 0.6 and \n",
    "                        landmarks[elbow_idx].visibility > 0.6 and \n",
    "                        landmarks[wrist_idx].visibility > 0.6):\n",
    "                        \n",
    "                        shoulder = (int(landmarks[shoulder_idx].x * frame_width),\n",
    "                                    int(landmarks[shoulder_idx].y * frame_height))\n",
    "                        elbow = (int(landmarks[elbow_idx].x * frame_width),\n",
    "                                 int(landmarks[elbow_idx].y * frame_height))\n",
    "                        wrist = (int(landmarks[wrist_idx].x * frame_width),\n",
    "                                 int(landmarks[wrist_idx].y * frame_height))\n",
    "                        \n",
    "                        angle = calculate_angle(shoulder, elbow, wrist)\n",
    "                        angle = min(angle, 180)  # Normalize angle range\n",
    "                        \n",
    "                        if side == 'left':\n",
    "                            left_angles.append(angle)\n",
    "                        else:\n",
    "                            right_angles.append(angle)\n",
    "                        \n",
    "                        cv2.putText(frame, f'{side.capitalize()} Angle: {int(angle)}', (elbow[0] - 50, elbow[1] - 20), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                        \n",
    "                        cv2.circle(frame, shoulder, 5, (255, 0, 0), -1)\n",
    "                        cv2.circle(frame, elbow, 5, (0, 255, 0), -1)\n",
    "                        cv2.circle(frame, wrist, 5, (0, 0, 255), -1)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "        # Display muscle concentration bars based on peak at 30-degree angle\n",
    "        left_concentration = max(0, 100 - abs(left_angles[-1] - 30)) if left_angles else 0\n",
    "        right_concentration = max(0, 100 - abs(right_angles[-1] - 30)) if right_angles else 0\n",
    "        \n",
    "        left_peak_concentration = max(left_peak_concentration, left_concentration)\n",
    "        right_peak_concentration = max(right_peak_concentration, right_concentration)\n",
    "        \n",
    "        left_bar_length = int(left_concentration)\n",
    "        right_bar_length = int(right_concentration)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 50), (50 + left_bar_length * 2, 70), (0, 255, 0), -1)\n",
    "        cv2.putText(frame, f'Left Concentration: {int(left_concentration)}%', (50, 45), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 100), (50 + right_bar_length * 2, 120), (255, 0, 0), -1)\n",
    "        cv2.putText(frame, f'Right Concentration: {int(right_concentration)}%', (50, 95), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow(\"Live Pose Tracking\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    live_tracking()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Optimize TensorFlow threading (if used elsewhere in the project)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"  # OpenMP threads\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"8\"  \n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"8\"  \n",
    "\n",
    "# Enable OpenCV multi-threading\n",
    "cv2.setNumThreads(8)  # Adjust based on your CPU cores\n",
    "\n",
    "# Improve NumPy operations\n",
    "np.seterr(over='ignore')  # Prevent floating-point warnings\n",
    "\n",
    "\n",
    "# Initialize Pose Model\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))  # Ensure valid range\n",
    "    return angle\n",
    "\n",
    "# Function for Real-time Pose Detection & Rep Counting\n",
    "def live_tracking():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    left_angles = []\n",
    "    right_angles = []\n",
    "    left_peak_concentration = 0\n",
    "    right_peak_concentration = 0\n",
    "    \n",
    "    cv2.namedWindow(\"Live Pose Tracking\", cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty(\"Live Pose Tracking\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb_frame)\n",
    "        \n",
    "        try:\n",
    "            if results.pose_landmarks and results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].visibility > 0.6:\n",
    "                mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "                \n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                \n",
    "                joints = {\n",
    "                    'left': (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),\n",
    "                    'right': (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST)\n",
    "                }\n",
    "                \n",
    "                for side, (shoulder_idx, elbow_idx, wrist_idx) in joints.items():\n",
    "                    if (landmarks[shoulder_idx].visibility > 0.6 and \n",
    "                        landmarks[elbow_idx].visibility > 0.6 and \n",
    "                        landmarks[wrist_idx].visibility > 0.6):\n",
    "                        \n",
    "                        shoulder = (int(landmarks[shoulder_idx].x * frame_width),\n",
    "                                    int(landmarks[shoulder_idx].y * frame_height))\n",
    "                        elbow = (int(landmarks[elbow_idx].x * frame_width),\n",
    "                                 int(landmarks[elbow_idx].y * frame_height))\n",
    "                        wrist = (int(landmarks[wrist_idx].x * frame_width),\n",
    "                                 int(landmarks[wrist_idx].y * frame_height))\n",
    "                        \n",
    "                        angle = calculate_angle(shoulder, elbow, wrist)\n",
    "                        angle = min(angle, 180)  # Normalize angle range\n",
    "                        \n",
    "                        if side == 'left':\n",
    "                            left_angles.append(angle)\n",
    "                        else:\n",
    "                            right_angles.append(angle)\n",
    "                        \n",
    "                        cv2.putText(frame, f'{side.capitalize()} Angle: {int(angle)}', (elbow[0] - 50, elbow[1] - 20), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                        \n",
    "                        cv2.circle(frame, shoulder, 5, (255, 0, 0), -1)\n",
    "                        cv2.circle(frame, elbow, 5, (0, 255, 0), -1)\n",
    "                        cv2.circle(frame, wrist, 5, (0, 0, 255), -1)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "        # Display muscle concentration bars based on peak at 30-degree angle\n",
    "        left_concentration = max(0, 100 - abs(left_angles[-1] - 30)) if left_angles else 0\n",
    "        right_concentration = max(0, 100 - abs(right_angles[-1] - 30)) if right_angles else 0\n",
    "        \n",
    "        left_peak_concentration = max(left_peak_concentration, left_concentration)\n",
    "        right_peak_concentration = max(right_peak_concentration, right_concentration)\n",
    "        \n",
    "        left_bar_length = int(left_concentration)\n",
    "        right_bar_length = int(right_concentration)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 50), (50 + left_bar_length * 2, 70), (0, 255, 0), -1)\n",
    "        cv2.putText(frame, f'Left Concentration: {int(left_concentration)}%', (50, 45), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.rectangle(frame, (50, 100), (50 + right_bar_length * 2, 120), (255, 0, 0), -1)\n",
    "        cv2.putText(frame, f'Right Concentration: {int(right_concentration)}%', (50, 95), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow(\"Live Pose Tracking\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    live_tracking()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
